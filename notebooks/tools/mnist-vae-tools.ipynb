{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm as tqdmx\n",
    "\n",
    "bs = 100\n",
    "#Tools Dataset\n",
    "dataset = torchvision.datasets.ImageFolder('../../data/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.Resize(28),\n",
    "                                               transforms.CenterCrop(28),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=bs, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notify_run import Notify\n",
    "notify = Notify()\n",
    "notify.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "z_dim = 2\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, 51)):\n",
    "    notify.send('Training epoch {}'.format(epoch))\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(data_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    tqdmx.write('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), \"./mnist-vae-tools_zdim2.torch\")\n",
    "notify.send(\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_state_dict(torch.load('./mnist-vae-tools_zdim2.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Plot the image here using matplotlib.\n",
    "def plot_image(tensor, save=None):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    # imshow needs a numpy array with the channel dimension\n",
    "    # as the the last dimension so we have to transpose things.\n",
    "    plt.imshow(tensor.numpy().transpose(1, 2, 0))\n",
    "    \n",
    "    if save is not None:\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for i in range(0, 1000, 50):\n",
    "    fixed_x = dataset[i][0]\n",
    "    recon_x = vae(fixed_x.cuda())[0].view(3, 28, 28)\n",
    "    compare = torch.cat([fixed_x.cuda(), recon_x], dim=1)\n",
    "    summary.append(compare)\n",
    "    \n",
    "plot_image(torch.cat(summary, dim=2).cpu().detach(), save='summary_zdim2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 8x8 digits\n",
    "digit_size = 28\n",
    "\n",
    "# linearly spaced coordinates on the unit square were transformed\n",
    "# through the inverse CDF (ppf) of the Gaussian to produce values\n",
    "# of the latent variables z, since the prior of the latent space\n",
    "# is Gaussian\n",
    "u_grid = np.dstack(np.meshgrid(np.linspace(0.05, 0.95, n),\n",
    "                               np.linspace(0.05, 0.95, n)))\n",
    "z_grid = norm.ppf(u_grid)\n",
    "\n",
    "x_decoded = vae.decoder(torch.from_numpy(z_grid.reshape(n*n, 2)).float().cuda())\n",
    "x_decoded = x_decoded.reshape(n, n, digit_size, digit_size)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(np.block(list(map(list, x_decoded.detach().cpu().numpy()))), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
