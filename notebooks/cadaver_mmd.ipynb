{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('/users/dli44/tool-presence'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src import constants as c\n",
    "from src import utils\n",
    "from src import visualization as v\n",
    "from src import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = utils.setup_argparse()\n",
    "args = parser.parse_args(args=['--root=/users/dli44/tool-presence/',\n",
    "                               '--data-dir=data/cadaver_data/',\n",
    "                               '--image-size=64',\n",
    "                               '--loss-function=mmd',\n",
    "                               '--z-dim=10'\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, dataloaders = utils.setup_data(args, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.VAE(image_channels=args.image_channels,\n",
    "              image_size=args.image_size,\n",
    "              h_dim1=1024,\n",
    "              h_dim2=128,\n",
    "              zdim=args.z_dim).to(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "model_name = \"mmd_zdim10_beta_1.0_epoch_50.torch\"\n",
    "model_path = os.path.join(args.root, 'data/cadaver_mmd_vae', model_name)\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def compute_samples(data, num_samples, debug=False):\n",
    "    \"\"\" Sample from importance distribution z_samples ~ q(z|X) and\n",
    "        compute p(z_samples), q(z_samples) for importance sampling\n",
    "    \"\"\"\n",
    "#     dataloader_iterator = iter(dataloader)\n",
    "#     try:\n",
    "#         data, _ = next(dataloader_iterator)\n",
    "#     except StopIteration:\n",
    "#         dataloader_iterator = iter(dataloader)\n",
    "#         data, target = next(dataloader_iterator)\n",
    "    \n",
    "    z_mean, z_log_sigma = model.encode(data.to(c.device))\n",
    "    z_mean, z_log_sigma = utils.torch_to_numpy(z_mean), utils.torch_to_numpy(z_log_sigma)\n",
    "    z_samples = []\n",
    "    qz = []\n",
    "    \n",
    "    \n",
    "    for m, s in zip(z_mean, z_log_sigma):\n",
    "        z_vals = [np.random.normal(m[i], np.exp(s[i]), num_samples)\n",
    "                  for i in range(len(m))]\n",
    "        qz_vals = [norm.pdf(z_vals[i], loc=m[i], scale=np.exp(s[i]))\n",
    "                  for i in range(len(m))]\n",
    "        z_samples.append(z_vals)\n",
    "        qz.append(qz_vals)\n",
    "        \n",
    "    \n",
    "    z_samples = np.array(z_samples)\n",
    "    pz = norm.pdf(z_samples)\n",
    "    qz = np.array(qz)\n",
    "    \n",
    "    z_samples = np.swapaxes(z_samples, 1, 2)\n",
    "    pz = np.swapaxes(pz, 1, 2)\n",
    "    qz = np.swapaxes(qz, 1, 2)\n",
    "    \n",
    "    return z_samples, pz, qz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_logpx(dataloader, num_samples, debug=False):\n",
    "    \n",
    "    # Calculate importance sample\n",
    "    # \\log p(x) = E_p[p(x|z)]\n",
    "    # = \\log(\\int p(x|z) p(z) dz)\n",
    "    # = \\log(\\int p(x|z) p(z) / q(z|x) q(z|x) dz)\n",
    "    # = E_q[p(x|z) p(z) / q(z|x)]\n",
    "    # ~= \\log(1/n * \\sum_i p(x|z_i) p(z_i)/q(z_i))\n",
    "    # = \\log p(x) = \\log(1/n * \\sum_i e^{\\log p(x|z_i) + \\log p(z_i) - \\log q(z_i)})\n",
    "    # = \\log p(x) = -\\logn + \\logsumexp_i(\\log p(x|z_i) + \\log p(z_i) - \\log q(z_i))\n",
    "    # See: scipy.special.logsumexp\n",
    "    result = []\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        z_samples, pz, qz = compute_samples(data, num_samples)\n",
    "        assert z_samples.shape == pz.shape\n",
    "        assert pz.shape == qz.shape\n",
    "        for i in range(len(data)):\n",
    "            datum = utils.torch_to_numpy(data[i]).reshape(args.image_size * args.image_size * args.image_channels)\n",
    "            x_predict = model.decode(torch.from_numpy(z_samples[i]).float().to(c.device))\n",
    "            x_predict = utils.torch_to_numpy(x_predict).reshape(-1, args.image_size * args.image_size * args.image_channels)\n",
    "            x_predict = np.clip(x_predict, np.finfo(float).eps, 1. - np.finfo(float).eps)\n",
    "            p_vals = pz[i]\n",
    "            q_vals = qz[i]\n",
    "\n",
    "            # \\log p(x|z) = Binary cross entropy\n",
    "            logp_xz = np.sum(datum * np.log(x_predict) + (1. - datum) * np.log(1.0 - x_predict), axis=-1)\n",
    "            logpz = np.sum(np.log(p_vals), axis=-1)\n",
    "            logqz = np.sum(np.log(q_vals), axis=-1)\n",
    "            argsum = logp_xz + logpz - logqz\n",
    "            logpx = -np.log(num_samples) + logsumexp(argsum)\n",
    "            result.append(logpx)\n",
    "        \n",
    "        if debug:\n",
    "            print(x_predict.shape)\n",
    "            print(p_vals.shape)\n",
    "            print(q_vals.shape)\n",
    "            print(logp_xz.shape)\n",
    "            print(logpz.shape)\n",
    "            print(logqz.shape)\n",
    "            print(\"logp_xz\", logp_xz)\n",
    "            print(\"logpz\", logpz)\n",
    "            print(\"logqz\", logqz)\n",
    "            print(argsum.shape)\n",
    "            print(\"logpx\", logpx)\n",
    "            \n",
    "    return np.array(result)\n",
    "            \n",
    "logpx = estimate_logpx(dataloaders['val'], num_samples=64, debug=True)\n",
    "#pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(logpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-np.nanmean(logpx)/(args.image_size * args.image_size * args.image_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(args.root, args.data_dir, 'surgical_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Initial Images\\nStart, End\")\n",
    "plt.imshow(np.hstack([datasets['val'][1][0].numpy().transpose(1,2,0), \n",
    "                      datasets['val'][9][0].numpy().transpose(1,2,0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "recon1, z, _, _ = model(datasets['val'][1][0].unsqueeze(0).to(c.device))\n",
    "recon2, z, _, _ = model(datasets['val'][9][0].unsqueeze(0).to(c.device))\n",
    "\n",
    "recon1 = utils.torch_to_image(recon1)\n",
    "recon2 = utils.torch_to_image(recon2)\n",
    "\n",
    "originals = np.hstack([utils.torch_to_image(datasets['val'][1][0]), \n",
    "                       utils.torch_to_image(datasets['val'][9][0])])\n",
    "recons = np.hstack([recon1, recon2])\n",
    "\n",
    "plt.imshow(np.vstack([originals, recons]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = v.latent_interpolation(datasets['val'][1][0], \n",
    "                                datasets['val'][9][0], \n",
    "                                model=model)\n",
    "\n",
    "fig = v.plot_interpolation(images, \"Interpolation\\nBeta=5\")\n",
    "\n",
    "plt.savefig(os.path.join(args.root,\n",
    "                         'data/mmd_vae',\n",
    "                         'mmd_tool_motion.png'), bbox_inches='tight', dpi=400, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = utils.torch_to_numpy(v.get_latent_vector(datasets['val'][1][0], model))[0]\n",
    "b = utils.torch_to_numpy(v.get_latent_vector(datasets['val'][9][0], model))[0]\n",
    "diff = a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(a)\n",
    "plt.plot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Initial Images\\nStart, End\")\n",
    "plt.imshow(np.hstack([datasets['train'][360][0].numpy().transpose(1,2,0), \n",
    "                      datasets['train'][368][0].numpy().transpose(1,2,0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = v.latent_interpolation(datasets['train'][360][0], \n",
    "                                datasets['train'][368][0], \n",
    "                                model=model)\n",
    "\n",
    "fig = v.plot_interpolation(images, \"Interpolation\\nBeta=5\")\n",
    "\n",
    "plt.savefig(os.path.join(args.root,\n",
    "                         'data/mmd_vae',\n",
    "                         'mmd_tool_motion2.png'), bbox_inches='tight', dpi=400, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = v.explore_latent_dimension(datasets['train'][360][0], model, zdim=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.plot_interpolation(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
