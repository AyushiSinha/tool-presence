{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('/users/dli44/tool-presence'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src import constants as c\n",
    "from src import utils\n",
    "from src import visualization as v\n",
    "from src import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = utils.setup_argparse()\n",
    "args = parser.parse_args(args=['--root=/users/dli44/tool-presence/',\n",
    "                               '--data-dir=data/youtube_data/',\n",
    "                               '--image-size=64',\n",
    "                               '--loss-function=mmd',\n",
    "                               '--z-dim=10'\n",
    "                              ])\n",
    "datasets, dataloaders = utils.setup_data(args, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = [2,5,10,20,40,80]\n",
    "betas=[1.0,2.0,5.0,10.0,20.0,40.0]\n",
    "lambdas = [1.0,5.0,10.0,20.0,100.0,500.0]\n",
    "mmd_model_paths = [['mmd/weights/final_beta_{}_zdim_{}_epoch_80.torch'.format(l, z) \n",
    "                   for l in lambdas] for z in zs]\n",
    "elbo_model_paths = [['elbo/weights/final_beta_{}_zdim_{}_epoch_80.torch'.format(beta, z) \n",
    "                    for beta in betas] for z in zs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_table = []\n",
    "\n",
    "for i,zdim in enumerate(zs):\n",
    "    for j, path in enumerate(mmd_model_paths[i]):\n",
    "        model = m.VAE(image_channels=args.image_channels,\n",
    "                  image_size=args.image_size,\n",
    "                  h_dim1=1024,\n",
    "                  h_dim2=128,\n",
    "                  zdim=zdim).to(c.device)\n",
    "        model.load_state_dict(torch.load(os.path.join(args.root, path)))\n",
    "        print(path)\n",
    "\n",
    "        logpx = utils.estimate_logpx(dataloaders['val'], model, args, 128)\n",
    "\n",
    "        # Compute rl and mmd\n",
    "        recon_loss, mmd_div, kl_div = 0,0,0\n",
    "        n = len(dataloaders['val'].dataset)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _) in enumerate(dataloaders['val']):\n",
    "                data = data.to(c.device)\n",
    "                recon_batch, z, mu, logvar = model(data)\n",
    "                loss_params = {'recon': recon_batch,\n",
    "                               'x': data,\n",
    "                               'z': z,\n",
    "                               'mu': mu,\n",
    "                               'logvar': logvar,\n",
    "                               'batch_size': args.batch_size,\n",
    "                               'input_size': args.image_size,\n",
    "                               'zdim': zdim,\n",
    "                               'beta': betas[j]}\n",
    "#                 print(loss_params)\n",
    "                _, mmd, rl = m.mmd_loss(**loss_params)\n",
    "                _, _, kld = m.vae_loss(**loss_params)\n",
    "                print(rl.item(), mmd.item(), kld.item())\n",
    "                recon_loss += rl.item()\n",
    "                mmd_div += mmd.item()\n",
    "                kl_div += kld.item()\n",
    "\n",
    "        mmd_table.append([recon_loss/n, mmd_div/n, kl_div/n, np.nanmean(logpx)])\n",
    "        # Free GPU memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        foo = range(10000000)\n",
    "        del foo\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mmd_table.pkl', 'rb') as f:\n",
    "    mmd_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo_table = []\n",
    "\n",
    "for i,zdim in enumerate(zs):\n",
    "    for j, path in enumerate(elbo_model_paths[i]):\n",
    "        model = m.VAE(image_channels=args.image_channels,\n",
    "                  image_size=args.image_size,\n",
    "                  h_dim1=1024,\n",
    "                  h_dim2=128,\n",
    "                  zdim=zdim).to(c.device)\n",
    "        model.load_state_dict(torch.load(os.path.join(args.root, path)))\n",
    "        print(path)\n",
    "\n",
    "        logpx = utils.estimate_logpx(dataloaders['val'], model, args, 128)\n",
    "\n",
    "        # Compute rl and mmd\n",
    "        recon_loss, mmd_div, kl_div = 0,0,0\n",
    "        n = len(dataloaders['val'].dataset)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _) in enumerate(dataloaders['val']):\n",
    "                data = data.to(c.device)\n",
    "                recon_batch, z, mu, logvar = model(data)\n",
    "                loss_params = {'recon': recon_batch,\n",
    "                               'x': data,\n",
    "                               'z': z,\n",
    "                               'mu': mu,\n",
    "                               'logvar': logvar,\n",
    "                               'batch_size': args.batch_size,\n",
    "                               'input_size': args.image_size,\n",
    "                               'zdim': zdim,\n",
    "                               'beta': betas[j]}\n",
    "#                 print(loss_params)\n",
    "                _, mmd, rl = m.mmd_loss(**loss_params)\n",
    "                _, _, kld = m.vae_loss(**loss_params)\n",
    "#                 print(rl.item(), mmd.item(), kld.item())\n",
    "                recon_loss += rl.item()\n",
    "                mmd_div += mmd.item()\n",
    "                kl_div += kld.item()\n",
    "\n",
    "        elbo_table.append([recon_loss/n, mmd_div/n, kl_div/n, np.nanmean(logpx)])\n",
    "        # Free GPU memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        foo = range(10000000)\n",
    "        del foo\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_notation(number, sig_fig=2):\n",
    "    ret_string = \"{0:.{1:d}e}\".format(number, sig_fig)\n",
    "    a,b = ret_string.split(\"e\")\n",
    "#     print(a,b)\n",
    "    b = int(b) #removed leading \"+\" and strips leading zeros too.\n",
    "    return \"$\" + a + \"\\\\times 10^{\" + str(b) + \"}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_notation(elbo_table[5][0]* pixels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"$z$ & $\\\\beta$ & Reconstruction Loss & MMD Distance & KL-Divergence & $\\log(p(x))$ (est.) & bits/pixel\\\\\\\\\\\\midrule\")\n",
    "pixels = args.image_size * args.image_size * args.image_channels\n",
    "for i, zdim in enumerate(zs):\n",
    "    for j, path in enumerate(betas):\n",
    "        print(\"{} & {} & {} & {} & {} & {} & {:.2f}\\\\\\\\\".format(zdim, \n",
    "                                                                int(path), \n",
    "                                                                sci_notation(elbo_table[j+6*i][0] * pixels), \n",
    "                                                                sci_notation(elbo_table[j+6*i][1]), \n",
    "                                                                sci_notation(elbo_table[j+6*i][2]), \n",
    "                                                                sci_notation(elbo_table[j+6*i][3]),\n",
    "                                                                -elbo_table[j+6*i][3]/pixels * np.log(10)/np.log(2)))\n",
    "    print('\\\\midrule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out.txt', 'w') as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
